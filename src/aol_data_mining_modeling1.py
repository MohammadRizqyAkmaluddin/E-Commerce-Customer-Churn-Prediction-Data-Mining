# -*- coding: utf-8 -*-
"""AOL Data Mining_Modeling1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bXBGnbQK4Jhdvv4EdahdxLhxLwFwefFl

# **IMPORT LIBRARIES AND READ FILE**
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from scipy.stats import randint, uniform
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.neighbors import KNeighborsClassifier

from imblearn.over_sampling import SMOTE

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

url = 'https://raw.githubusercontent.com/Cloudyum/E-Commerce-Customer-Churn-Prediction-Data-Mining/refs/heads/main/output/cleaned_data.csv'

df = pd.read_csv('https://raw.githubusercontent.com/Cloudyum/E-Commerce-Customer-Churn-Prediction-Data-Mining/refs/heads/main/output/cleaned_data.csv')

df.head()
df.info()
df.describe()

#DOUBLE-CHECK DATA
print(df.isna().sum())
print(df['Churn'].value_counts(normalize=True))

"""Bisa kita lihat bahwa datanya masih imbalance atau tidak seimbang, karena customer yang tidak churn (dilambangkan oleh '0') memiliki angka yang lebih tinggi yaitu 0.83 daripada customer yang churn (dilambangkan oleh angka '1') yaitu 0.17

# **CHOOSING TARGET**
"""

target_col = 'Churn'
X = df.drop(target_col, axis=1)
y = df[target_col]

"""# **SPLITTING DATA**"""

# 70% train, 30% sisa
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y,
    test_size=0.3,
    stratify=y,
    random_state=42
)

# 2) Dari 30%, dibagi jadi 15% val + 15% test
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp,
    test_size=0.5,
    stratify=y_temp,
    random_state=42
)

print(f"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")

"""# **SAMPLING DATA**"""

# NOTE: hanya pada training data saja
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

print("\nDistribusi setelah SMOTE:")
print(y_train_res.value_counts())

"""# **STANDARIZATION**"""

rf_model = RandomForestClassifier(random_state=42)

logreg_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LogisticRegression(max_iter=5000))
])

svm_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', SVC(kernel='rbf', probability=True, class_weight='balanced'))
])

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

lgbm_model = LGBMClassifier(random_state=42)

knn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', KNeighborsClassifier(n_neighbors=5))
])

"""# **CROSS VALIDATION**"""

param_grids = {
    "Random Forest": {
        "n_estimators": [100, 200],
        "max_depth": [None, 10, 20],
        "min_samples_split": [2, 5],
        "min_samples_leaf": [1, 2]
    },
    "Logistic Regression": {
        "model__C": [0.01, 0.1, 1, 10],
        "model__solver": ["lbfgs", "liblinear"]
    },
    "SVM": {
        "model__C": [0.1, 1, 10],
        "model__gamma": ["scale", "auto"]
    },
    "XGBoost": {
        "n_estimators": [100, 200],
        "max_depth": [3, 6, 10],
        "learning_rate": [0.01, 0.1, 0.2]
    },
    "LightGBM": {
        "n_estimators": [100, 200],
        "max_depth": [-1, 10, 20],
        "learning_rate": [0.01, 0.1, 0.2]
    },
    "KNN": {
        "model__n_neighbors": [3, 5, 7, 9],
        "model__weights": ["uniform", "distance"]
    }
}

cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

"""# **TUNING PARAMETER**"""

def tune_model_once(model, name, X_train, y_train):
    """Hyperparameter tuning sekali per model"""
    if name not in param_grids:
        print(f"Tidak ada param_grid untuk {name}, pakai default model.")
        return model

    print(f"\nTuning {name} ...")
    param_grid = param_grids[name]
    cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grid,
        scoring='f1',
        cv=cv_inner,
        n_jobs=-1,
        verbose=1
    )
    grid_search.fit(X_train, y_train)
    print(f"Best params for {name}: {grid_search.best_params_}")
    return grid_search.best_estimator_

"""# **MODELING**"""

models = [
    (rf_model, "Random Forest"),
    (logreg_pipeline, "Logistic Regression"),
    (svm_pipeline, "SVM"),
    (xgb_model, "XGBoost"),
    (lgbm_model, "LightGBM"),
    (knn_pipeline, "KNN")
]

def evaluate_model_cv(model, name, X, y):
    acc_scores, prec_scores, rec_scores, f1_scores, roc_scores = [], [], [], [], []

    for train_idx, test_idx in cv_outer.split(X, y):
        X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]
        y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]

        # fit model hasil tuning
        model.fit(X_train_fold, y_train_fold)
        y_pred = model.predict(X_test_fold)

        # ROC AUC
        if hasattr(model, "predict_proba"):
            y_score = model.predict_proba(X_test_fold)[:, 1]
        elif hasattr(model, "decision_function"):
            y_score = model.decision_function(X_test_fold)
        else:
            y_score = y_pred

        acc_scores.append(accuracy_score(y_test_fold, y_pred))
        prec_scores.append(precision_score(y_test_fold, y_pred))
        rec_scores.append(recall_score(y_test_fold, y_pred))
        f1_scores.append(f1_score(y_test_fold, y_pred))
        roc_scores.append(roc_auc_score(y_test_fold, y_score))

    metrics = {
        "Model": name,
        "Accuracy": np.mean(acc_scores),
        "Precision": np.mean(prec_scores),
        "Recall": np.mean(rec_scores),
        "F1 Score": np.mean(f1_scores),
        "ROC AUC": np.mean(roc_scores)
    }

    print(f"\n=== {name} (CV 5-Fold) ===")
    for k, v in metrics.items():
        if k != "Model":
            print(f"{k}: {v:.4f}")

    return metrics

tuned_models = []
for model, name in models:
    best_model = tune_model_once(model, name, X, y)
    tuned_models.append((best_model, name))

results_cv = []
for model, name in tuned_models:
    result = evaluate_model_cv(model, name, X, y)
    results_cv.append(result)

"""# **EVALUATION**"""

results_cv_df = pd.DataFrame(results_cv).sort_values(by="F1 Score", ascending=False).reset_index(drop=True)

print("Hasil Akhir Setelah Hyperparameter Tuning:")
print(results_cv_df)

"""# **SAVE FILE**"""

import joblib
joblib.dump(best_model, "best_lightgbm.pkl")

"""# **MODELING OLD**"""

#RANDOM FOREST

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - Random Forest')
plt.show()

#LOGISTIC REGRESSION

logreg = LogisticRegression(max_iter=500, random_state=42)
logreg.fit(X_train_scaled, y_train)

y_pred_log = logreg.predict(X_test_scaled)

print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_log))
print(classification_report(y_test, y_pred_log))
sns.heatmap(confusion_matrix(y_test, y_pred_log), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix - Logistic Regression')
plt.show()

# SVM

svm_model = SVC(kernel='rbf', random_state=42)
svm_model.fit(X_train_scaled, y_train)

y_pred_svm = svm_model.predict(X_test_scaled)

print("SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print(classification_report(y_test, y_pred_svm))
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Oranges')
plt.title('Confusion Matrix - SVM')
plt.show()